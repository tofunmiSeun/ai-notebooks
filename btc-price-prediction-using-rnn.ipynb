{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download historical daily BTC/USD prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ['ALHPA_AVANTAGE_API_KEY']\n",
    "url = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={}'.format(api_key)\n",
    "r = requests.get(url)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We got 1000 data points'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data = data['Time Series (Digital Currency Daily)']\n",
    "closing_prices = []\n",
    "for day in daily_data.keys():\n",
    "    closing_price = round(float(daily_data[day]['4b. close (USD)']), 2)\n",
    "    closing_prices.append(closing_price)\n",
    "\n",
    "\"We got {} data points\".format(len(closing_prices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into batches of 5 sequential price points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [closing_prices[x:x+time_steps] for x in range(0, len(closing_prices), time_steps)]\n",
    "train_test_split_index = int(0.8 * len(chunks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,\n",
       " [23248.86, 23141.57, 23492.09, 23554.85, 23157.07],\n",
       " 40,\n",
       " [22719.71, 23455.52, 23821.61, 23107.39, 22797.16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = chunks[0:train_test_split_index]\n",
    "test_data = chunks[train_test_split_index:]\n",
    "len(training_data), training_data[0], len(test_data), test_data[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn training and test data into pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([160, 5]), torch.Size([40, 5]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = torch.Tensor(training_data) / 10000\n",
    "test = torch.Tensor(test_data) / 10000\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_output = nn.Linear(1 + time_steps, 1)\n",
    "input_to_hidden = nn.Linear(1 + time_steps, time_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input, hidden):\n",
    "    combined_input = torch.cat((input, hidden), 1)\n",
    "    output = input_to_output(combined_input)\n",
    "    new_hidden = input_to_hidden(combined_input)\n",
    "    return output, new_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1642]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.zeros(1, time_steps)\n",
    "for i in range(0, time_steps):\n",
    "    input = train[0][i:i+1].unsqueeze(1)\n",
    "    output, hidden = forward(input, hidden)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model in randomized batches in one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.0005\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "input_to_output = nn.Linear(1 + time_steps, 1)\n",
    "input_to_hidden = nn.Linear(1 + time_steps, time_steps)\n",
    "\n",
    "def run_epoch():\n",
    "    randomized_training_indices = torch.randperm(train.shape[0])\n",
    "    losses = []\n",
    "    # for each training batch\n",
    "    for new_batch_start in range(0, len(randomized_training_indices), batch_size):\n",
    "        batch_indices = [randomized_training_indices[x].item() for x in range(new_batch_start, new_batch_start+batch_size)]\n",
    "        \n",
    "        predictions = torch.zeros(len(batch_indices))\n",
    "        outputs = torch.zeros(len(batch_indices))\n",
    "        index = 0\n",
    "\n",
    "        input_to_hidden.zero_grad()\n",
    "        input_to_output.zero_grad()\n",
    "    \n",
    "        # for training data in batch\n",
    "        for batch_index in batch_indices:\n",
    "\n",
    "            hidden = torch.zeros(1, time_steps)\n",
    "            single_train_data = train[batch_index]\n",
    "            prediction = 0\n",
    "            # for each time step\n",
    "            for step in range(0, len(single_train_data - 1)):\n",
    "                input = single_train_data[step:step+1].unsqueeze(1)\n",
    "                prediction, hidden = forward(input, hidden)          \n",
    "            \n",
    "            actual = single_train_data[-1]\n",
    "            predictions[index] = prediction\n",
    "            outputs[index] = actual\n",
    "            index += 1\n",
    "        \n",
    "        # calculate error\n",
    "        loss = mse(predictions, outputs)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # back propagation to adjust weights\n",
    "        loss.backward()\n",
    "        for p in input_to_hidden.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        input_to_hidden.grad = None\n",
    "\n",
    "        for p in input_to_output.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        input_to_output.grad = None\n",
    "    \n",
    "    return sum(losses)/ len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, average loss: 9.259889274835587\n",
      "Epoch: 5, average loss: 0.01913500757655129\n",
      "Epoch: 10, average loss: 0.018774945696350187\n",
      "Epoch: 15, average loss: 0.018284777557710186\n",
      "Epoch: 20, average loss: 0.01785020186798647\n",
      "Epoch: 25, average loss: 0.01738853580900468\n",
      "Epoch: 30, average loss: 0.016981839609798044\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 31):\n",
    "    avg_loss = run_epoch()\n",
    "    if i % 5 == 0:\n",
    "        print(\"Epoch: {}, average loss: {}\".format(i, avg_loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([22719.7090, 23455.5195, 23821.6094, 23107.3906]), prediction: 21042.892578125, actual: 22797.16015625, % error=-7.695\n",
      "input: tensor([21335.5176, 19426.4297, 19273.1406, 19174.9902]), prediction: 17638.33203125, actual: 18808.689453125, % error=-6.222\n",
      "input: tensor([18036.5293, 18254.6309, 18541.2793, 18324.1094]), prediction: 16529.193359375, actual: 19166.900390625, % error=-13.762\n",
      "input: tensor([19359.4004, 19147.6602, 18650.5195, 19421.9004]), prediction: 17210.080078125, actual: 19204.08984375, % error=-10.383\n",
      "input: tensor([18764.9609, 19695.8691, 18184.9902, 17719.8496]), prediction: 16548.2578125, actual: 17139.51953125, % error=-3.45\n",
      "input: tensor([17149.4707, 18719.1094, 19160.0098, 18368.0000]), prediction: 16684.68359375, actual: 18414.4296875, % error=-9.393\n",
      "input: tensor([18703.8008, 18655.6699, 17802.8203, 17776.1191]), prediction: 16282.5107421875, actual: 17659.380859375, % error=-7.797\n",
      "input: tensor([16713.5703, 15957.0000, 16070.4502, 16320.7002]), prediction: 14626.544921875, actual: 16291.8603515625, % error=-10.222\n",
      "input: tensor([15684.2402, 15297.2100, 15328.4102, 15475.0986]), prediction: 13899.7919921875, actual: 14818.2998046875, % error=-6.198\n",
      "input: tensor([15579.9199, 15590.0195, 14144.0098, 14023.5303]), prediction: 13118.353515625, actual: 13549.369140625, % error=-3.181\n",
      "input: tensor([13761.5000, 13791.0000, 13560.0996, 13455.6992]), prediction: 12248.30078125, actual: 13266.400390625, % error=-7.674\n",
      "input: tensor([13636.1699, 13052.1904, 13028.8301, 13111.7305]), prediction: 11850.5927734375, actual: 12923.0703125, % error=-8.299\n",
      "input: tensor([12968.5195, 12780.9600, 11909.9902, 11751.4697]), prediction: 10956.78125, actual: 11503.1396484375, % error=-4.75\n",
      "input: tensor([11360.2002, 11319.3203, 11505.1201, 11417.8896]), prediction: 10292.728515625, actual: 11420.5595703125, % error=-9.875\n",
      "input: tensor([11528.2500, 11369.0195, 11293.2197, 11050.6387]), prediction: 10145.0703125, actual: 10925.5703125, % error=-7.144\n",
      "input: tensor([10666.3896, 10599.6602, 10792.2100, 10666.6299]), prediction: 9640.275390625, actual: 10542.060546875, % error=-8.554\n",
      "input: tensor([10570.4014, 10619.1299, 10776.5898, 10840.4805]), prediction: 9678.236328125, actual: 10696.1201171875, % error=-9.516\n",
      "input: tensor([10774.2500, 10728.5996, 10686.6689, 10736.3203]), prediction: 9662.4716796875, actual: 10241.4599609375, % error=-5.653\n",
      "input: tensor([10529.6104, 10417.2197, 10920.2803, 11080.6504]), prediction: 9760.435546875, actual: 10933.3896484375, % error=-10.728\n",
      "input: tensor([10939.9902, 10954.0098, 10785.3086, 10671.7695]), prediction: 9729.7080078125, actual: 10332.830078125, % error=-5.837\n",
      "input: tensor([10440.9189, 10387.8887, 10336.8701, 10219.1992]), prediction: 9299.9443359375, actual: 10126.650390625, % error=-8.164\n",
      "input: tensor([10373.4414, 10256.2002, 10166.6904, 10446.2500]), prediction: 9287.19140625, actual: 10140.849609375, % error=-8.418\n",
      "input: tensor([11388.5400, 11921.9697, 11649.5098, 11711.1602]), prediction: 10520.919921875, actual: 11465.8408203125, % error=-8.241\n",
      "input: tensor([11526.9102, 11330.3809, 11461.4297, 11318.4199]), prediction: 10273.064453125, actual: 11748.2001953125, % error=-12.556\n",
      "input: tensor([11648.1309, 11662.9600, 11531.3398, 11853.5498]), prediction: 10523.880859375, actual: 11754.58984375, % error=-10.47\n",
      "input: tensor([11945.0088, 12281.1289, 11911.0000, 11852.4004]), prediction: 10774.4794921875, actual: 11760.5400390625, % error=-8.384\n",
      "input: tensor([11780.0000, 11564.3301, 11392.0801, 11892.9199]), prediction: 10495.5771484375, actual: 11681.6796875, % error=-10.154\n",
      "input: tensor([11761.4102, 11594.2295, 11762.4609, 11744.9102]), prediction: 10567.92578125, actual: 11191.9697265625, % error=-5.576\n",
      "input: tensor([11219.8086, 11071.3496, 11801.1699, 11335.4600]), prediction: 10303.841796875, actual: 11099.6103515625, % error=-7.169\n",
      "input: tensor([11100.5303, 10906.2695, 11029.9600,  9931.5400]), prediction: 9595.24609375, actual: 9700.419921875, % error=-1.084\n",
      "input: tensor([9537.7998, 9603.2695, 9518.1602, 9390.0000]), prediction: 8552.7265625, actual: 9160.7802734375, % error=-6.638\n",
      "input: tensor([9208.9902, 9170.2803, 9154.3203, 9133.7197]), prediction: 8252.044921875, actual: 9197.599609375, % error=-10.28\n",
      "input: tensor([9255.8496, 9242.6201, 9302.7500, 9234.0303]), prediction: 8346.0078125, actual: 9288.33984375, % error=-10.145\n",
      "input: tensor([9232.4297, 9436.0596, 9257.3896, 9344.2002]), prediction: 8391.1435546875, actual: 9069.41015625, % error=-7.479\n",
      "input: tensor([9135.4600, 9058.2598, 9086.5400, 9232.0000]), prediction: 8234.1328125, actual: 9138.5498046875, % error=-9.897\n",
      "input: tensor([9192.5596, 9116.3496, 9012.0000, 9162.2100]), prediction: 8206.0693359375, actual: 9249.490234375, % error=-11.281\n",
      "input: tensor([9296.4902, 9624.8896, 9685.6904, 9294.6904]), prediction: 8546.478515625, actual: 9358.9501953125, % error=-8.681\n",
      "input: tensor([9310.2305, 9386.3203, 9465.1396, 9525.5898]), prediction: 8514.224609375, actual: 9426.01953125, % error=-9.673\n",
      "input: tensor([9342.0996, 9473.3398, 9465.1299, 9280.4004]), prediction: 8456.9052734375, actual: 9885.0, % error=-14.447\n",
      "input: tensor([9772.4297, 9782.0098, 9746.9902, 9666.2998]), prediction: 8766.66015625, actual: 9621.16015625, % error=-8.881\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, test.shape[0]):\n",
    "    single_test_data = test[i] * 10000\n",
    "    x = single_test_data[0:len(single_test_data) - 1]\n",
    "    actual = single_test_data[-1]\n",
    "\n",
    "    hidden = torch.zeros(1, time_steps)\n",
    "    prediction = 0\n",
    "    # for each time step\n",
    "    for item in x:\n",
    "        input = torch.Tensor([item]).unsqueeze(1)\n",
    "        prediction, hidden = forward(input, hidden)          \n",
    "    \n",
    "    actual = single_test_data[-1]\n",
    "    percentage_error = round(((prediction.item() - actual.item()) * 100) / actual.item(), 3)\n",
    "    print(\"input: {}, prediction: {}, actual: {}, % error={}\".format(x, prediction.item(), actual, percentage_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12b84d27cf94b059d9386ef0e125d5acfb36035007af7d95356a9eda8a09a0a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
