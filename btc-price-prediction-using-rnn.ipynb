{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download historical daily BTC/USD prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ['ALHPA_AVANTAGE_API_KEY']\n",
    "url = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={}'.format(api_key)\n",
    "r = requests.get(url)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We got 1000 data points'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data = data['Time Series (Digital Currency Daily)']\n",
    "closing_prices = []\n",
    "for day in daily_data.keys():\n",
    "    closing_price = round(float(daily_data[day]['4b. close (USD)']), 2)\n",
    "    closing_prices.append(closing_price)\n",
    "\n",
    "\"We got {} data points\".format(len(closing_prices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into batches of 5 sequential price points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [closing_prices[x:x+time_steps] for x in range(0, len(closing_prices), time_steps)]\n",
    "train_test_split_index = int(0.8 * len(chunks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,\n",
       " [23248.86, 23141.57, 23492.09, 23554.85, 23157.07],\n",
       " 40,\n",
       " [22719.71, 23455.52, 23821.61, 23107.39, 22797.16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = chunks[0:train_test_split_index]\n",
    "test_data = chunks[train_test_split_index:]\n",
    "len(training_data), training_data[0], len(test_data), test_data[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn training and test data into pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([160, 5]), torch.Size([40, 5]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = torch.Tensor(training_data) / 10000\n",
    "test = torch.Tensor(test_data) / 10000\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_output = nn.Linear(1 + time_steps, 1)\n",
    "input_to_hidden = nn.Linear(1 + time_steps, time_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input, hidden):\n",
    "    combined_input = torch.cat((input, hidden), 1)\n",
    "    output = input_to_output(combined_input)\n",
    "    new_hidden = input_to_hidden(combined_input)\n",
    "    return output, new_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1642]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.zeros(1, time_steps)\n",
    "for i in range(0, time_steps):\n",
    "    input = train[0][i:i+1].unsqueeze(1)\n",
    "    output, hidden = forward(input, hidden)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model in randomized batches in one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.0005\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "def run_epoch(input_to_output, input_to_hidden):\n",
    "    randomized_training_indices = torch.randperm(train.shape[0])\n",
    "    losses = []\n",
    "    # for each training batch\n",
    "    for new_batch_start in range(0, len(randomized_training_indices), batch_size):\n",
    "        batch_indices = [randomized_training_indices[x].item() for x in range(new_batch_start, new_batch_start+batch_size)]\n",
    "        \n",
    "        predictions = torch.zeros(len(batch_indices))\n",
    "        outputs = torch.zeros(len(batch_indices))\n",
    "        index = 0\n",
    "\n",
    "        input_to_hidden.zero_grad()\n",
    "        input_to_output.zero_grad()\n",
    "    \n",
    "        # for training data in batch\n",
    "        for batch_index in batch_indices:\n",
    "\n",
    "            hidden = torch.zeros(1, time_steps)\n",
    "            single_train_data = train[batch_index]\n",
    "            prediction = 0\n",
    "            # for each time step\n",
    "            for step in range(0, len(single_train_data - 1)):\n",
    "                input = single_train_data[step:step+1].unsqueeze(1)\n",
    "                prediction, hidden = forward(input, hidden)          \n",
    "            \n",
    "            actual = single_train_data[-1]\n",
    "            predictions[index] = prediction\n",
    "            outputs[index] = actual\n",
    "            index += 1\n",
    "        \n",
    "        # calculate error\n",
    "        loss = mse(predictions, outputs)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # back propagation to adjust weights\n",
    "        loss.backward()\n",
    "        for p in input_to_hidden.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        input_to_hidden.grad = None\n",
    "\n",
    "        for p in input_to_output.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        input_to_output.grad = None\n",
    "    \n",
    "    return sum(losses)/ len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, average loss: 0.007031659944914281\n",
      "Epoch: 100, average loss: 0.005904969017137773\n",
      "Epoch: 150, average loss: 0.005137139196449425\n",
      "Epoch: 200, average loss: 0.0045657866285182536\n",
      "Epoch: 250, average loss: 0.004190652878605761\n",
      "Epoch: 300, average loss: 0.0038961354075581767\n",
      "Epoch: 350, average loss: 0.0036733333399752155\n",
      "Epoch: 400, average loss: 0.003508449943183223\n",
      "Epoch: 450, average loss: 0.0033735507531673647\n",
      "Epoch: 500, average loss: 0.003259252367570298\n"
     ]
    }
   ],
   "source": [
    "input_to_output = nn.Linear(1 + time_steps, 1)\n",
    "input_to_hidden = nn.Linear(1 + time_steps, time_steps)\n",
    "for i in range(1, 501):\n",
    "    avg_loss = run_epoch(input_to_output, input_to_hidden)\n",
    "    if i % 50 == 0:\n",
    "        print(\"Epoch: {}, average loss: {}\".format(i, avg_loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([22719.7090, 23455.5195, 23821.6094, 23107.3906]), prediction: 24215.455055236816, actual: 22797.16015625, % error=6.221\n",
      "input: tensor([21335.5176, 19426.4297, 19273.1406, 19174.9902]), prediction: 19850.02040863037, actual: 18808.689453125, % error=5.536\n",
      "input: tensor([18036.5293, 18254.6309, 18541.2793, 18324.1094]), prediction: 18993.122577667236, actual: 19166.900390625, % error=-0.907\n",
      "input: tensor([19359.4004, 19147.6602, 18650.5195, 19421.9004]), prediction: 19815.4878616333, actual: 19204.08984375, % error=3.184\n",
      "input: tensor([18764.9609, 19695.8691, 18184.9902, 17719.8496]), prediction: 18703.560829162598, actual: 17139.51953125, % error=9.125\n",
      "input: tensor([17149.4707, 18719.1094, 19160.0098, 18368.0000]), prediction: 19288.1441116333, actual: 18414.4296875, % error=4.745\n",
      "input: tensor([18703.8008, 18655.6699, 17802.8203, 17776.1191]), prediction: 18476.26566886902, actual: 17659.380859375, % error=4.626\n",
      "input: tensor([16713.5703, 15957.0000, 16070.4502, 16320.7002]), prediction: 16699.587106704712, actual: 16291.8603515625, % error=2.503\n",
      "input: tensor([15684.2402, 15297.2100, 15328.4102, 15475.0986]), prediction: 15874.501466751099, actual: 14818.2998046875, % error=7.128\n",
      "input: tensor([15579.9199, 15590.0195, 14144.0098, 14023.5303]), prediction: 14659.135341644287, actual: 13549.369140625, % error=8.191\n",
      "input: tensor([13761.5000, 13791.0000, 13560.0996, 13455.6992]), prediction: 13905.264139175415, actual: 13266.400390625, % error=4.816\n",
      "input: tensor([13636.1699, 13052.1904, 13028.8301, 13111.7305]), prediction: 13428.131341934204, actual: 12923.0703125, % error=3.908\n",
      "input: tensor([12968.5195, 12780.9600, 11909.9902, 11751.4697]), prediction: 12218.56951713562, actual: 11503.1396484375, % error=6.219\n",
      "input: tensor([11360.2002, 11319.3203, 11505.1201, 11417.8896]), prediction: 11709.030866622925, actual: 11420.5595703125, % error=2.526\n",
      "input: tensor([11528.2500, 11369.0195, 11293.2197, 11050.6387]), prediction: 11420.543193817139, actual: 10925.5703125, % error=4.53\n",
      "input: tensor([10666.3896, 10599.6602, 10792.2100, 10666.6299]), prediction: 10936.696529388428, actual: 10542.060546875, % error=3.743\n",
      "input: tensor([10570.4014, 10619.1299, 10776.5898, 10840.4805]), prediction: 11045.243740081787, actual: 10696.1201171875, % error=3.264\n",
      "input: tensor([10774.2500, 10728.5996, 10686.6689, 10736.3203]), prediction: 10965.37470817566, actual: 10241.4599609375, % error=7.068\n",
      "input: tensor([10529.6104, 10417.2197, 10920.2803, 11080.6504]), prediction: 11209.746599197388, actual: 10933.3896484375, % error=2.528\n",
      "input: tensor([10939.9902, 10954.0098, 10785.3086, 10671.7695]), prediction: 10983.797311782837, actual: 10332.830078125, % error=6.3\n",
      "input: tensor([10440.9189, 10387.8887, 10336.8701, 10219.1992]), prediction: 10495.296716690063, actual: 10126.650390625, % error=3.64\n",
      "input: tensor([10373.4414, 10256.2002, 10166.6904, 10446.2500]), prediction: 10568.763017654419, actual: 10140.849609375, % error=4.22\n",
      "input: tensor([11388.5400, 11921.9697, 11649.5098, 11711.1602]), prediction: 12021.498680114746, actual: 11465.8408203125, % error=4.846\n",
      "input: tensor([11526.9102, 11330.3809, 11461.4297, 11318.4199]), prediction: 11632.375717163086, actual: 11748.2001953125, % error=-0.986\n",
      "input: tensor([11648.1309, 11662.9600, 11531.3398, 11853.5498]), prediction: 12033.144235610962, actual: 11754.58984375, % error=2.37\n",
      "input: tensor([11945.0088, 12281.1289, 11911.0000, 11852.4004]), prediction: 12228.96933555603, actual: 11760.5400390625, % error=3.983\n",
      "input: tensor([11780.0000, 11564.3301, 11392.0801, 11892.9199]), prediction: 11999.621391296387, actual: 11681.6796875, % error=2.722\n",
      "input: tensor([11761.4102, 11594.2295, 11762.4609, 11744.9102]), prediction: 12022.08161354065, actual: 11191.9697265625, % error=7.417\n",
      "input: tensor([11219.8086, 11071.3496, 11801.1699, 11335.4600]), prediction: 11712.57734298706, actual: 11099.6103515625, % error=5.522\n",
      "input: tensor([11100.5303, 10906.2695, 11029.9600,  9931.5400]), prediction: 10584.335327148438, actual: 9700.419921875, % error=9.112\n",
      "input: tensor([9537.7998, 9603.2695, 9518.1602, 9390.0000]), prediction: 9637.306928634644, actual: 9160.7802734375, % error=5.202\n",
      "input: tensor([9208.9902, 9170.2803, 9154.3203, 9133.7197]), prediction: 9312.628507614136, actual: 9197.599609375, % error=1.251\n",
      "input: tensor([9255.8496, 9242.6201, 9302.7500, 9234.0303]), prediction: 9429.035186767578, actual: 9288.33984375, % error=1.515\n",
      "input: tensor([9232.4297, 9436.0596, 9257.3896, 9344.2002]), prediction: 9512.650966644287, actual: 9069.41015625, % error=4.887\n",
      "input: tensor([9135.4600, 9058.2598, 9086.5400, 9232.0000]), prediction: 9339.081048965454, actual: 9138.5498046875, % error=2.194\n",
      "input: tensor([9192.5596, 9116.3496, 9012.0000, 9162.2100]), prediction: 9280.593395233154, actual: 9249.490234375, % error=0.336\n",
      "input: tensor([9296.4902, 9624.8896, 9685.6904, 9294.6904]), prediction: 9635.24341583252, actual: 9358.9501953125, % error=2.952\n",
      "input: tensor([9310.2305, 9386.3203, 9465.1396, 9525.5898]), prediction: 9679.213762283325, actual: 9426.01953125, % error=2.686\n",
      "input: tensor([9342.0996, 9473.3398, 9465.1299, 9280.4004]), prediction: 9537.973403930664, actual: 9885.0, % error=-3.511\n",
      "input: tensor([9772.4297, 9782.0098, 9746.9902, 9666.2998]), prediction: 9899.429082870483, actual: 9621.16015625, % error=2.892\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, test.shape[0]):\n",
    "    single_test_data = test[i]\n",
    "    x = single_test_data[0:len(single_test_data) - 1]\n",
    "    actual = single_test_data[-1]\n",
    "\n",
    "    hidden = torch.zeros(1, time_steps)\n",
    "    prediction = 0\n",
    "    # for each time step\n",
    "    for item in x:\n",
    "        input = torch.Tensor([item]).unsqueeze(1)\n",
    "        prediction, hidden = forward(input, hidden)          \n",
    "    \n",
    "    actual = single_test_data[-1]\n",
    "    percentage_error = round(((prediction.item() - actual.item()) * 100) / actual.item(), 3)\n",
    "    print(\"input: {}, prediction: {}, actual: {}, % error={}\".format(x * 10000, prediction.item() * 10000, actual * 10000, percentage_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12b84d27cf94b059d9386ef0e125d5acfb36035007af7d95356a9eda8a09a0a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
