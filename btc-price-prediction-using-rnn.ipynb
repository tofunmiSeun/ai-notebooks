{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download historical daily BTC/USD prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ['ALHPA_AVANTAGE_API_KEY']\n",
    "url = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={}'.format(api_key)\n",
    "r = requests.get(url)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We got 1000 data points'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data = data['Time Series (Digital Currency Daily)']\n",
    "closing_prices = []\n",
    "for day in daily_data.keys():\n",
    "    closing_price = round(float(daily_data[day]['4b. close (USD)']), 2)\n",
    "    closing_prices.append(closing_price)\n",
    "\n",
    "\"We got {} data points\".format(len(closing_prices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into batches of 5 sequential price points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [closing_prices[x:x+time_steps] for x in range(0, len(closing_prices), time_steps)]\n",
    "train_test_split_index = int(0.8 * len(chunks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,\n",
       " [23248.86, 23141.57, 23492.09, 23554.85, 23157.07],\n",
       " 40,\n",
       " [22719.71, 23455.52, 23821.61, 23107.39, 22797.16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = chunks[0:train_test_split_index]\n",
    "test_data = chunks[train_test_split_index:]\n",
    "len(training_data), training_data[0], len(test_data), test_data[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn training and test data into pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([160, 5]), torch.Size([40, 5]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = torch.Tensor(training_data) / 10000\n",
    "test = torch.Tensor(test_data) / 10000\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_output = nn.Linear(1 + time_steps, 1)\n",
    "input_to_hidden = nn.Linear(1 + time_steps, time_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input, hidden):\n",
    "    combined_input = torch.cat((input, hidden), 1)\n",
    "    output = input_to_output(combined_input)\n",
    "    new_hidden = input_to_hidden(combined_input)\n",
    "    return output, new_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1072]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.zeros(1, time_steps)\n",
    "for i in range(0, time_steps):\n",
    "    input = train[0][i:i+1].unsqueeze(1)\n",
    "    output, hidden = forward(input, hidden)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model in randomized batches in one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.0005\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "input_to_output = nn.Linear(1 + time_steps, 1)\n",
    "input_to_hidden = nn.Linear(1 + time_steps, time_steps)\n",
    "\n",
    "def run_epoch():\n",
    "    randomized_training_indices = torch.randperm(train.shape[0])\n",
    "    losses = []\n",
    "    # for each training batch\n",
    "    for new_batch_start in range(0, len(randomized_training_indices), batch_size):\n",
    "        batch_indices = [randomized_training_indices[x].item() for x in range(new_batch_start, new_batch_start+batch_size)]\n",
    "        \n",
    "        predictions = torch.zeros(len(batch_indices))\n",
    "        outputs = torch.zeros(len(batch_indices))\n",
    "        index = 0\n",
    "\n",
    "        input_to_hidden.zero_grad()\n",
    "        input_to_output.zero_grad()\n",
    "    \n",
    "        # for training data in batch\n",
    "        for batch_index in batch_indices:\n",
    "\n",
    "            hidden = torch.zeros(1, time_steps)\n",
    "            single_train_data = train[batch_index]\n",
    "            prediction = 0\n",
    "            # for each time step\n",
    "            for step in range(0, len(single_train_data - 1)):\n",
    "                input = single_train_data[step:step+1].unsqueeze(1)\n",
    "                prediction, hidden = forward(input, hidden)          \n",
    "            \n",
    "            actual = single_train_data[-1]\n",
    "            predictions[index] = prediction\n",
    "            outputs[index] = actual\n",
    "            index += 1\n",
    "        \n",
    "        # calculate error\n",
    "        loss = mse(predictions, outputs)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # back propagation to adjust weights\n",
    "        loss.backward()\n",
    "        for p in input_to_hidden.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        input_to_hidden.grad = None\n",
    "\n",
    "        for p in input_to_output.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        input_to_output.grad = None\n",
    "    \n",
    "    return sum(losses)/ len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, average loss: 7.283649772405624\n",
      "Epoch: 5, average loss: 0.2329488219693303\n",
      "Epoch: 10, average loss: 0.008982465020380914\n",
      "Epoch: 15, average loss: 0.0038491451559821144\n",
      "Epoch: 20, average loss: 0.0036611920295399614\n",
      "Epoch: 25, average loss: 0.0035718394865398295\n",
      "Epoch: 30, average loss: 0.0034942865095217712\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 31):\n",
    "    avg_loss = run_epoch()\n",
    "    if i % 5 == 0:\n",
    "        print(\"Epoch: {}, average loss: {}\".format(i, avg_loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([22719.7090, 23455.5195, 23821.6094, 23107.3906]), prediction: 23965.88671875, actual: 22797.16015625, percentage error=5.127\n",
      "input: tensor([21335.5176, 19426.4297, 19273.1406, 19174.9902]), prediction: 19779.97265625, actual: 18808.689453125, percentage error=5.164\n",
      "input: tensor([18036.5293, 18254.6309, 18541.2793, 18324.1094]), prediction: 18929.361328125, actual: 19166.900390625, percentage error=-1.239\n",
      "input: tensor([19359.4004, 19147.6602, 18650.5195, 19421.9004]), prediction: 19840.6484375, actual: 19204.08984375, percentage error=3.315\n",
      "input: tensor([18764.9609, 19695.8691, 18184.9902, 17719.8496]), prediction: 18347.43359375, actual: 17139.51953125, percentage error=7.048\n",
      "input: tensor([17149.4707, 18719.1094, 19160.0098, 18368.0000]), prediction: 19098.91015625, actual: 18414.4296875, percentage error=3.717\n",
      "input: tensor([18703.8008, 18655.6699, 17802.8203, 17776.1191]), prediction: 18315.8359375, actual: 17659.380859375, percentage error=3.717\n",
      "input: tensor([16713.5703, 15957.0000, 16070.4502, 16320.7002]), prediction: 16763.529296875, actual: 16291.8603515625, percentage error=2.895\n",
      "input: tensor([15684.2402, 15297.2100, 15328.4102, 15475.0986]), prediction: 15913.7275390625, actual: 14818.2998046875, percentage error=7.392\n",
      "input: tensor([15579.9199, 15590.0195, 14144.0098, 14023.5303]), prediction: 14465.544921875, actual: 13549.369140625, percentage error=6.762\n",
      "input: tensor([13761.5000, 13791.0000, 13560.0996, 13455.6992]), prediction: 13885.2763671875, actual: 13266.400390625, percentage error=4.665\n",
      "input: tensor([13636.1699, 13052.1904, 13028.8301, 13111.7305]), prediction: 13492.34765625, actual: 12923.0703125, percentage error=4.405\n",
      "input: tensor([12968.5195, 12780.9600, 11909.9902, 11751.4697]), prediction: 12136.9638671875, actual: 11503.1396484375, percentage error=5.51\n",
      "input: tensor([11360.2002, 11319.3203, 11505.1201, 11417.8896]), prediction: 11784.796875, actual: 11420.5595703125, percentage error=3.189\n",
      "input: tensor([11528.2500, 11369.0195, 11293.2197, 11050.6387]), prediction: 11438.5478515625, actual: 10925.5703125, percentage error=4.695\n",
      "input: tensor([10666.3896, 10599.6602, 10792.2100, 10666.6299]), prediction: 11019.14453125, actual: 10542.060546875, percentage error=4.526\n",
      "input: tensor([10570.4014, 10619.1299, 10776.5898, 10840.4805]), prediction: 11156.66796875, actual: 10696.1201171875, percentage error=4.306\n",
      "input: tensor([10774.2500, 10728.5996, 10686.6689, 10736.3203]), prediction: 11051.19921875, actual: 10241.4599609375, percentage error=7.906\n",
      "input: tensor([10529.6104, 10417.2197, 10920.2803, 11080.6504]), prediction: 11385.7255859375, actual: 10933.3896484375, percentage error=4.137\n",
      "input: tensor([10939.9902, 10954.0098, 10785.3086, 10671.7695]), prediction: 11019.23828125, actual: 10332.830078125, percentage error=6.643\n",
      "input: tensor([10440.9189, 10387.8887, 10336.8701, 10219.1992]), prediction: 10554.71875, actual: 10126.650390625, percentage error=4.227\n",
      "input: tensor([10373.4414, 10256.2002, 10166.6904, 10446.2500]), prediction: 10702.078125, actual: 10140.849609375, percentage error=5.534\n",
      "input: tensor([11388.5400, 11921.9697, 11649.5098, 11711.1602]), prediction: 12050.69140625, actual: 11465.8408203125, percentage error=5.101\n",
      "input: tensor([11526.9102, 11330.3809, 11461.4297, 11318.4199]), prediction: 11694.2685546875, actual: 11748.2001953125, percentage error=-0.459\n",
      "input: tensor([11648.1309, 11662.9600, 11531.3398, 11853.5498]), prediction: 12142.375, actual: 11754.58984375, percentage error=3.299\n",
      "input: tensor([11945.0088, 12281.1289, 11911.0000, 11852.4004]), prediction: 12221.96875, actual: 11760.5400390625, percentage error=3.924\n",
      "input: tensor([11780.0000, 11564.3301, 11392.0801, 11892.9199]), prediction: 12144.107421875, actual: 11681.6796875, percentage error=3.959\n",
      "input: tensor([11761.4102, 11594.2295, 11762.4609, 11744.9102]), prediction: 12106.63671875, actual: 11191.9697265625, percentage error=8.173\n",
      "input: tensor([11219.8086, 11071.3496, 11801.1699, 11335.4600]), prediction: 11786.0634765625, actual: 11099.6103515625, percentage error=6.184\n",
      "input: tensor([11100.5303, 10906.2695, 11029.9600,  9931.5400]), prediction: 10473.0439453125, actual: 9700.419921875, percentage error=7.965\n",
      "input: tensor([9537.7998, 9603.2695, 9518.1602, 9390.0000]), prediction: 9702.23046875, actual: 9160.7802734375, percentage error=5.911\n",
      "input: tensor([9208.9902, 9170.2803, 9154.3203, 9133.7197]), prediction: 9415.380859375, actual: 9197.599609375, percentage error=2.368\n",
      "input: tensor([9255.8496, 9242.6201, 9302.7500, 9234.0303]), prediction: 9529.693359375, actual: 9288.33984375, percentage error=2.598\n",
      "input: tensor([9232.4297, 9436.0596, 9257.3896, 9344.2002]), prediction: 9607.4560546875, actual: 9069.41015625, percentage error=5.933\n",
      "input: tensor([9135.4600, 9058.2598, 9086.5400, 9232.0000]), prediction: 9480.8779296875, actual: 9138.5498046875, percentage error=3.746\n",
      "input: tensor([9192.5596, 9116.3496, 9012.0000, 9162.2100]), prediction: 9407.025390625, actual: 9249.490234375, percentage error=1.703\n",
      "input: tensor([9296.4902, 9624.8896, 9685.6904, 9294.6904]), prediction: 9661.85546875, actual: 9358.9501953125, percentage error=3.237\n",
      "input: tensor([9310.2305, 9386.3203, 9465.1396, 9525.5898]), prediction: 9802.0205078125, actual: 9426.01953125, percentage error=3.989\n",
      "input: tensor([9342.0996, 9473.3398, 9465.1299, 9280.4004]), prediction: 9602.048828125, actual: 9885.0, percentage error=-2.862\n",
      "input: tensor([9772.4297, 9782.0098, 9746.9902, 9666.2998]), prediction: 9977.0126953125, actual: 9621.16015625, percentage error=3.699\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, test.shape[0]):\n",
    "    single_test_data = test[i] * 10000\n",
    "    x = single_test_data[0:len(single_test_data) - 1]\n",
    "    actual = single_test_data[-1]\n",
    "\n",
    "    hidden = torch.zeros(1, time_steps)\n",
    "    prediction = 0\n",
    "    # for each time step\n",
    "    for item in x:\n",
    "        input = torch.Tensor([item]).unsqueeze(1)\n",
    "        prediction, hidden = forward(input, hidden)          \n",
    "    \n",
    "    actual = single_test_data[-1]\n",
    "    percentage_error = round(((prediction.item() - actual.item()) * 100) / actual.item(), 3)\n",
    "    print(\"input: {}, prediction: {}, actual: {}, percentage error={}\".format(x, prediction.item(), actual, percentage_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12b84d27cf94b059d9386ef0e125d5acfb36035007af7d95356a9eda8a09a0a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
