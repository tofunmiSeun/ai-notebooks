{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download historical daily BTC/USD prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ['ALHPA_AVANTAGE_API_KEY']\n",
    "url = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={}'.format(api_key)\n",
    "r = requests.get(url)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = data['Time Series (Digital Currency Daily)']\n",
    "closing_prices = []\n",
    "for day in daily_data.keys():\n",
    "    closing_price = round(float(daily_data[day]['4b. close (USD)']), 2)\n",
    "    closing_prices.append(closing_price)\n",
    "\n",
    "\"We have {} data points\".format(len(closing_prices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into batches of 5 sequential price points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [closing_prices[x:x+time_steps] for x in range(0, len(closing_prices), time_steps)]\n",
    "train_test_split_index = int(0.8 * len(chunks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = chunks[0:train_test_split_index]\n",
    "test_data = chunks[train_test_split_index:]\n",
    "len(training_data), training_data[0], len(test_data), test_data[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn training and test data into pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.Tensor(training_data) / 10000\n",
    "test = torch.Tensor(test_data) / 10000\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_output = nn.Linear(1 + time_steps, 1)\n",
    "input_to_hidden = nn.Linear(1 + time_steps, time_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input, hidden):\n",
    "    combined_input = torch.cat((input, hidden), 1)\n",
    "    output = input_to_output(combined_input)\n",
    "    new_hidden = input_to_hidden(combined_input)\n",
    "    return output, new_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.zeros(1, time_steps)\n",
    "for i in range(0, time_steps):\n",
    "    input = train[0][i:i+1].unsqueeze(1)\n",
    "    output, hidden = forward(input, hidden)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model in randomized batches in one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.0005\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "input_to_output = nn.Linear(1 + time_steps, 1)\n",
    "input_to_hidden = nn.Linear(1 + time_steps, time_steps)\n",
    "\n",
    "def run_epoch():\n",
    "    randomized_training_indices = torch.randperm(train.shape[0])\n",
    "    losses = []\n",
    "    # for each training batch\n",
    "    for new_batch_start in range(0, len(randomized_training_indices), batch_size):\n",
    "        batch_indices = [randomized_training_indices[x].item() for x in range(new_batch_start, new_batch_start+batch_size)]\n",
    "        \n",
    "        predictions = torch.zeros(len(batch_indices))\n",
    "        outputs = torch.zeros(len(batch_indices))\n",
    "        index = 0\n",
    "\n",
    "        input_to_hidden.zero_grad()\n",
    "        input_to_output.zero_grad()\n",
    "    \n",
    "        # for training data in batch\n",
    "        for batch_index in batch_indices:\n",
    "\n",
    "            hidden = torch.zeros(1, time_steps)\n",
    "            single_train_data = train[batch_index]\n",
    "            prediction = 0\n",
    "            # for each time step\n",
    "            for step in range(0, len(single_train_data - 1)):\n",
    "                input = single_train_data[step:step+1].unsqueeze(1)\n",
    "                prediction, hidden = forward(input, hidden)          \n",
    "            \n",
    "            actual = single_train_data[-1]\n",
    "            predictions[index] = prediction\n",
    "            outputs[index] = actual\n",
    "            index += 1\n",
    "        \n",
    "        # calculate error\n",
    "        loss = mse(predictions, outputs)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # back propagation to adjust weights\n",
    "        loss.backward()\n",
    "        for p in input_to_hidden.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        input_to_hidden.grad = None\n",
    "\n",
    "        for p in input_to_output.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        input_to_output.grad = None\n",
    "    \n",
    "    print(\"avg epoch loss: {}\".format(sum(losses)/ len(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 30):\n",
    "    run_epoch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, test.shape[0]):\n",
    "    single_test_data = test[i]\n",
    "    print(single_test_data)\n",
    "    hidden = torch.zeros(1, time_steps)\n",
    "    prediction = 0\n",
    "    # for each time step\n",
    "    for step in range(0, len(single_test_data) - 1):\n",
    "        input = single_test_data[step:step+1].unsqueeze(1)\n",
    "        prediction, hidden = forward(input, hidden)          \n",
    "    \n",
    "    actual = single_test_data[-1]\n",
    "    percentage_error = round(((prediction.item() - actual.item()) * 100) / actual.item(), 3)\n",
    "    print(\"prediction: {}, actual: {}, percentage error={}\".format(prediction  * 10000, actual * 10000, percentage_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12b84d27cf94b059d9386ef0e125d5acfb36035007af7d95356a9eda8a09a0a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
